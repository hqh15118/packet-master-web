2019-06-27 15:10:07.173 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 1304 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:10:07.175 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:10:09.267 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:10:09.277 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:10:09.367 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 67ms. Found 0 repository interfaces.
2019-06-27 15:10:10.115 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$96a8e551] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:10:10.549 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:10:10.702 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:10:10.703 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:10:11.114 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:10:11.120 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:10:11.121 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:10:12.000 packet-master-web [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-27 15:11:50.538 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 16288 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:11:50.539 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:11:52.581 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:11:52.585 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:11:52.663 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 59ms. Found 0 repository interfaces.
2019-06-27 15:11:53.589 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$9433998] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:11:54.075 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:11:54.281 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:11:54.281 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:11:54.790 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:11:54.796 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:11:54.796 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:11:55.415 packet-master-web [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-27 15:12:28.162 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 16164 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:12:28.164 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:12:29.853 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:12:29.859 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:12:29.940 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 60ms. Found 0 repository interfaces.
2019-06-27 15:12:30.732 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$787bfba1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:12:31.190 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:12:31.356 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:12:31.356 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:12:31.825 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:12:31.830 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:12:31.830 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:12:32.388 packet-master-web [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-27 15:12:56.027 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 11224 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:12:56.028 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:12:57.715 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:12:57.718 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:12:57.807 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 69ms. Found 0 repository interfaces.
2019-06-27 15:12:58.539 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$b9c90f6f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:12:58.970 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:12:59.147 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:12:59.148 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:12:59.658 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:12:59.663 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:12:59.663 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:13:00.229 packet-master-web [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-27 15:14:22.115 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 4484 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:14:22.116 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:14:23.936 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:14:23.939 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:14:24.017 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 65ms. Found 0 repository interfaces.
2019-06-27 15:14:24.849 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$810d0c00] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:14:25.306 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:14:25.520 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:14:25.520 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:14:26.019 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:14:26.025 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:14:26.026 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:14:29.708 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:14:34.697 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:14:35.729 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:14:35.837 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:14:35.900 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:14:35.918 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:14:36.386 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:14:36.445 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 14.926 seconds (JVM running for 16.783)
2019-06-27 15:14:36.594 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:14:36.597 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:14:36.598 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:14:36.598 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@1f39b3ba, com.zjucsc.art_decode.artconfig.S7Config@34f2d3a6, com.zjucsc.art_decode.artconfig.S7Config@3da701a1, com.zjucsc.art_decode.artconfig.S7Config@53b579d2, com.zjucsc.art_decode.artconfig.S7Config@30b075b9, com.zjucsc.art_decode.artconfig.S7Config@6f51d1cc, com.zjucsc.art_decode.artconfig.S7Config@359fd0a2, com.zjucsc.art_decode.artconfig.S7Config@d082916, com.zjucsc.art_decode.artconfig.S7Config@17d25e1d] 
********************
2019-06-27 15:14:49.967 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：9384
****************
2019-06-27 15:14:50.007 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 15:14:50.009 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 15:18:08.736 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 8492 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:18:08.738 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:18:10.831 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:18:10.834 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:18:10.918 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 66ms. Found 0 repository interfaces.
2019-06-27 15:18:11.676 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$538479d2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:18:12.073 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:18:12.245 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:18:12.245 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:18:12.655 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:18:12.661 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:18:12.661 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:18:15.196 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:18:16.930 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:18:17.647 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:18:17.761 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:18:17.779 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:18:17.795 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:18:18.166 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:18:18.216 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 10.365 seconds (JVM running for 11.403)
2019-06-27 15:18:18.364 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:18:18.366 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:18:18.366 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:18:18.366 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@25435731, com.zjucsc.art_decode.artconfig.S7Config@6cc44207, com.zjucsc.art_decode.artconfig.S7Config@1ecec098, com.zjucsc.art_decode.artconfig.S7Config@71fb1da3, com.zjucsc.art_decode.artconfig.S7Config@5ef591af, com.zjucsc.art_decode.artconfig.S7Config@5cd6719d, com.zjucsc.art_decode.artconfig.S7Config@8ecc457, com.zjucsc.art_decode.artconfig.S7Config@10301d6f, com.zjucsc.art_decode.artconfig.S7Config@61b0af9f] 
********************
2019-06-27 15:18:18.703 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：15
****************
2019-06-27 15:18:18.715 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 15:18:18.717 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 15:19:16.207 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 2840 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:19:16.209 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:19:18.087 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:19:18.092 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:19:18.183 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 71ms. Found 0 repository interfaces.
2019-06-27 15:19:18.985 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$cc0abe07] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:19:19.399 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:19:19.581 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:19:19.582 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:19:20.059 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:19:20.064 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:19:20.065 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:19:23.079 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:19:25.365 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:19:26.263 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:19:26.370 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:19:26.397 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:19:26.412 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:19:26.836 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:19:26.894 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 11.197 seconds (JVM running for 12.836)
2019-06-27 15:19:27.029 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:19:27.031 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:19:27.031 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:19:27.031 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@24381e4a, com.zjucsc.art_decode.artconfig.S7Config@4010f232, com.zjucsc.art_decode.artconfig.S7Config@5b312863, com.zjucsc.art_decode.artconfig.S7Config@1cf7c055, com.zjucsc.art_decode.artconfig.S7Config@39dee5fd, com.zjucsc.art_decode.artconfig.S7Config@24be6e34, com.zjucsc.art_decode.artconfig.S7Config@39f3285d, com.zjucsc.art_decode.artconfig.S7Config@4b6fc231, com.zjucsc.art_decode.artconfig.S7Config@6b7ebac1] 
********************
2019-06-27 15:19:45.991 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:19:46.007 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：10
****************
2019-06-27 15:19:46.223 packet-master-web [kafka-producer-network-thread | client1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: 8imxqaZ9QB-eWIBXAVsL-Q
2019-06-27 15:19:52.647 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 15:19:52.648 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 15:20:07.044 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 12188 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:20:07.045 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:20:08.588 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:20:08.591 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:20:08.673 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 65ms. Found 0 repository interfaces.
2019-06-27 15:20:09.405 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$d4252db2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:20:09.826 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:20:10.003 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:20:10.003 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:20:10.441 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:20:10.447 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:20:10.448 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:20:13.008 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:20:14.823 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:20:15.549 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:20:15.666 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:20:15.691 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:20:15.706 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:20:16.152 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:20:16.201 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 9.687 seconds (JVM running for 10.943)
2019-06-27 15:20:16.322 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:20:16.324 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:20:16.325 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:20:16.325 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@6cc44207, com.zjucsc.art_decode.artconfig.S7Config@1ecec098, com.zjucsc.art_decode.artconfig.S7Config@7ebaf0d, com.zjucsc.art_decode.artconfig.S7Config@71fb1da3, com.zjucsc.art_decode.artconfig.S7Config@5ef591af, com.zjucsc.art_decode.artconfig.S7Config@8ecc457, com.zjucsc.art_decode.artconfig.S7Config@61b0af9f, com.zjucsc.art_decode.artconfig.S7Config@21d3d6ec, com.zjucsc.art_decode.artconfig.S7Config@49f1184e] 
********************
2019-06-27 15:20:16.730 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：16
****************
2019-06-27 15:20:16.898 packet-master-web [kafka-producer-network-thread | client1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: 8imxqaZ9QB-eWIBXAVsL-Q
2019-06-27 15:20:21.213 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:20:36.307 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 10792 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:20:36.309 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:20:38.499 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:20:38.503 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:20:38.588 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 68ms. Found 0 repository interfaces.
2019-06-27 15:20:39.294 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$d4252db2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:20:39.676 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:20:39.832 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:20:39.832 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:20:40.303 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:20:40.309 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:20:40.309 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:20:43.063 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:20:44.914 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:20:45.651 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:20:45.751 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:20:45.771 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:20:45.788 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:20:46.205 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:20:46.253 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 10.569 seconds (JVM running for 11.756)
2019-06-27 15:20:46.369 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:20:46.371 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:20:46.372 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:20:46.372 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@6cc44207, com.zjucsc.art_decode.artconfig.S7Config@1ecec098, com.zjucsc.art_decode.artconfig.S7Config@7ebaf0d, com.zjucsc.art_decode.artconfig.S7Config@71fb1da3, com.zjucsc.art_decode.artconfig.S7Config@5ef591af, com.zjucsc.art_decode.artconfig.S7Config@8ecc457, com.zjucsc.art_decode.artconfig.S7Config@61b0af9f, com.zjucsc.art_decode.artconfig.S7Config@21d3d6ec, com.zjucsc.art_decode.artconfig.S7Config@49f1184e] 
********************
2019-06-27 15:20:46.766 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：18
****************
2019-06-27 15:20:46.942 packet-master-web [kafka-producer-network-thread | client1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: 8imxqaZ9QB-eWIBXAVsL-Q
2019-06-27 15:20:51.263 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:26:36.190 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 9696 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:26:36.192 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:26:37.848 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:26:37.851 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:26:37.926 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 57ms. Found 0 repository interfaces.
2019-06-27 15:26:38.519 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$97a12308] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:26:38.860 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:26:39.018 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:26:39.018 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:26:39.420 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:26:39.425 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:26:39.426 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:26:41.933 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:26:43.658 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:26:44.428 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:26:44.515 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:26:44.531 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:26:44.545 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:26:44.883 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:26:44.929 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 9.418 seconds (JVM running for 11.427)
2019-06-27 15:26:45.085 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:26:45.087 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:26:45.088 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:26:45.089 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@694b1ddb, com.zjucsc.art_decode.artconfig.S7Config@4d2bc56a, com.zjucsc.art_decode.artconfig.S7Config@7ebaf0d, com.zjucsc.art_decode.artconfig.S7Config@2c6aa46c, com.zjucsc.art_decode.artconfig.S7Config@5690c2a8, com.zjucsc.art_decode.artconfig.S7Config@17e2835c, com.zjucsc.art_decode.artconfig.S7Config@7cbfbcd1, com.zjucsc.art_decode.artconfig.S7Config@49f1184e, com.zjucsc.art_decode.artconfig.S7Config@2f112ade] 
********************
2019-06-27 15:26:45.503 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：15
****************
2019-06-27 15:26:45.782 packet-master-web [kafka-producer-network-thread | client1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: 8imxqaZ9QB-eWIBXAVsL-Q
2019-06-27 15:26:49.937 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:38:05.070 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 15712 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:38:05.071 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:38:06.723 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:38:06.727 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:38:06.811 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 66ms. Found 0 repository interfaces.
2019-06-27 15:38:07.582 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$6d70c1e4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:38:08.043 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:38:08.214 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:38:08.214 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:38:08.739 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:38:08.745 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:38:08.745 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:38:11.893 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:38:13.981 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:38:14.921 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:38:15.097 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:38:15.139 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:38:15.160 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:38:15.676 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:38:15.743 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 11.173 seconds (JVM running for 13.201)
2019-06-27 15:38:15.887 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:38:15.890 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:38:15.890 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:38:15.891 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@46878216, com.zjucsc.art_decode.artconfig.S7Config@35599228, com.zjucsc.art_decode.artconfig.S7Config@267309f7, com.zjucsc.art_decode.artconfig.S7Config@5d10e2b6, com.zjucsc.art_decode.artconfig.S7Config@1a1c308b, com.zjucsc.art_decode.artconfig.S7Config@2b69ff13, com.zjucsc.art_decode.artconfig.S7Config@51ac72f7, com.zjucsc.art_decode.artconfig.S7Config@7136ad9a, com.zjucsc.art_decode.artconfig.S7Config@4fb42efa] 
********************
2019-06-27 15:38:42.928 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：14
****************
2019-06-27 15:38:43.170 packet-master-web [kafka-producer-network-thread | client1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: 8imxqaZ9QB-eWIBXAVsL-Q
2019-06-27 15:38:57.310 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:38:57.398 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 15:38:57.400 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 15:40:23.698 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 13876 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:40:23.700 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:40:25.383 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:40:25.391 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:40:25.504 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 85ms. Found 0 repository interfaces.
2019-06-27 15:40:26.344 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$810d0c00] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:40:26.807 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:40:26.983 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:40:26.983 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:40:27.513 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:40:27.519 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:40:27.519 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:40:30.495 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:40:32.360 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:40:33.205 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:40:33.317 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:40:33.338 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:40:33.353 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:40:33.763 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:40:33.814 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 10.675 seconds (JVM running for 12.516)
2019-06-27 15:40:33.947 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:40:33.949 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:40:33.949 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:40:33.949 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@1e9afe4e, com.zjucsc.art_decode.artconfig.S7Config@27ada0e8, com.zjucsc.art_decode.artconfig.S7Config@1eda853f, com.zjucsc.art_decode.artconfig.S7Config@3f0751b0, com.zjucsc.art_decode.artconfig.S7Config@2e845f1c, com.zjucsc.art_decode.artconfig.S7Config@1f67d37f, com.zjucsc.art_decode.artconfig.S7Config@5b8ba1d2, com.zjucsc.art_decode.artconfig.S7Config@57fb6900, com.zjucsc.art_decode.artconfig.S7Config@64641998] 
********************
2019-06-27 15:41:13.642 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:41:13.658 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：12
****************
2019-06-27 15:41:13.698 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 15:41:13.700 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 15:45:17.608 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 13996 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:45:17.609 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:45:19.390 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:45:19.394 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:45:19.474 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 62ms. Found 0 repository interfaces.
2019-06-27 15:45:20.356 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$f885aec3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:45:20.823 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:45:20.999 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:45:20.999 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:45:21.481 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:45:21.486 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:45:21.487 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:45:24.567 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:45:26.637 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:45:27.506 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:45:27.609 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:45:27.628 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:45:27.648 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:45:28.072 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:45:28.144 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 11.09 seconds (JVM running for 12.929)
2019-06-27 15:45:28.306 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:45:28.308 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:45:28.309 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:45:28.309 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@49c72fb7, com.zjucsc.art_decode.artconfig.S7Config@72321701, com.zjucsc.art_decode.artconfig.S7Config@68024e57, com.zjucsc.art_decode.artconfig.S7Config@63df2eb8, com.zjucsc.art_decode.artconfig.S7Config@2e2546bf, com.zjucsc.art_decode.artconfig.S7Config@4b74a4d, com.zjucsc.art_decode.artconfig.S7Config@565983f3, com.zjucsc.art_decode.artconfig.S7Config@a3e458, com.zjucsc.art_decode.artconfig.S7Config@2f83467] 
********************
2019-06-27 15:46:59.418 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:46:59.419 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：17
****************
2019-06-27 15:48:40.627 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 15:48:40.628 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 15:49:55.765 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 6320 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:49:55.767 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:49:57.545 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:49:57.550 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:49:57.628 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 63ms. Found 0 repository interfaces.
2019-06-27 15:49:58.442 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$9a3b0583] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:49:58.899 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:49:59.065 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:49:59.065 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:49:59.553 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:49:59.558 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:49:59.558 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:50:02.588 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:50:04.665 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:50:05.525 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:50:05.631 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:50:05.651 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:50:05.672 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:50:06.121 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:50:06.182 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 10.934 seconds (JVM running for 12.714)
2019-06-27 15:50:06.330 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:50:06.332 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:50:06.333 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:50:06.333 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@4e3bc13b, com.zjucsc.art_decode.artconfig.S7Config@117be84a, com.zjucsc.art_decode.artconfig.S7Config@5e0b7f58, com.zjucsc.art_decode.artconfig.S7Config@3e5febe9, com.zjucsc.art_decode.artconfig.S7Config@1e9e4468, com.zjucsc.art_decode.artconfig.S7Config@2e7dd504, com.zjucsc.art_decode.artconfig.S7Config@140fa482, com.zjucsc.art_decode.artconfig.S7Config@5643052d, com.zjucsc.art_decode.artconfig.S7Config@5fdff4f1] 
********************
2019-06-27 15:50:13.807 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：19
****************
2019-06-27 15:50:40.711 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:51:24.130 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 15:51:24.132 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 15:59:14.620 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 11248 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 15:59:14.621 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 15:59:16.527 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 15:59:16.530 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 15:59:16.597 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 52ms. Found 0 repository interfaces.
2019-06-27 15:59:17.358 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$d4252db2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 15:59:17.741 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:59:17.922 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:59:17.922 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:59:18.302 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 15:59:18.307 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 15:59:18.307 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 15:59:20.666 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 15:59:22.337 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 15:59:23.056 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 15:59:23.157 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 15:59:23.176 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 15:59:23.189 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 15:59:23.545 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 15:59:23.586 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 9.635 seconds (JVM running for 11.015)
2019-06-27 15:59:23.714 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 15:59:23.716 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 15:59:23.717 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 15:59:23.718 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@6cc44207, com.zjucsc.art_decode.artconfig.S7Config@1ecec098, com.zjucsc.art_decode.artconfig.S7Config@7ebaf0d, com.zjucsc.art_decode.artconfig.S7Config@71fb1da3, com.zjucsc.art_decode.artconfig.S7Config@5ef591af, com.zjucsc.art_decode.artconfig.S7Config@8ecc457, com.zjucsc.art_decode.artconfig.S7Config@61b0af9f, com.zjucsc.art_decode.artconfig.S7Config@21d3d6ec, com.zjucsc.art_decode.artconfig.S7Config@49f1184e] 
********************
2019-06-27 15:59:24.152 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：15
****************
2019-06-27 15:59:24.359 packet-master-web [kafka-producer-network-thread | client1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: 8imxqaZ9QB-eWIBXAVsL-Q
2019-06-27 15:59:28.598 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 15:59:34.153 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-stopService
请求参数:[null]
请求结果:{"code":500,"msg":"null not open"}
耗时：0
****************
2019-06-27 15:59:39.157 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：1
****************
2019-06-27 15:59:49.165 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 15:59:49.166 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 16:00:36.101 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 5260 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 16:00:36.103 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 16:00:38.051 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 16:00:38.055 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 16:00:38.135 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 64ms. Found 0 repository interfaces.
2019-06-27 16:00:38.807 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$5bcf0b88] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 16:00:39.176 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 16:00:39.330 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 16:00:39.330 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 16:00:39.719 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 16:00:39.727 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 16:00:39.727 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 16:00:42.286 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 16:00:44.011 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 16:00:44.674 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 16:00:44.785 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 16:00:44.808 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 16:00:44.835 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 16:00:45.230 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 16:00:45.275 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 9.781 seconds (JVM running for 10.925)
2019-06-27 16:00:45.389 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 16:00:45.391 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 16:00:45.392 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 16:00:45.392 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@694b1ddb, com.zjucsc.art_decode.artconfig.S7Config@6cc44207, com.zjucsc.art_decode.artconfig.S7Config@1ecec098, com.zjucsc.art_decode.artconfig.S7Config@7ebaf0d, com.zjucsc.art_decode.artconfig.S7Config@71fb1da3, com.zjucsc.art_decode.artconfig.S7Config@5690c2a8, com.zjucsc.art_decode.artconfig.S7Config@8ecc457, com.zjucsc.art_decode.artconfig.S7Config@21d3d6ec, com.zjucsc.art_decode.artconfig.S7Config@49f1184e] 
********************
2019-06-27 16:00:45.757 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：13
****************
2019-06-27 16:00:45.913 packet-master-web [kafka-producer-network-thread | client1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: 8imxqaZ9QB-eWIBXAVsL-Q
2019-06-27 16:00:50.288 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 16:00:50.758 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-stopService
请求参数:[null]
请求结果:{"code":500,"msg":"null not open"}
耗时：0
****************
2019-06-27 16:00:55.759 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：1
****************
2019-06-27 16:01:05.770 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 16:01:05.771 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 16:01:32.012 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 816 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 16:01:32.057 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 16:01:33.891 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 16:01:33.894 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 16:01:33.964 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 56ms. Found 0 repository interfaces.
2019-06-27 16:01:34.608 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$2a0d1419] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 16:01:34.969 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 16:01:35.138 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 16:01:35.138 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 16:01:35.536 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 16:01:35.541 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 16:01:35.541 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 16:01:37.926 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 16:01:39.662 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 16:01:40.356 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 16:01:40.438 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 16:01:40.464 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 16:01:40.484 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 16:01:40.910 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 16:01:40.953 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 9.684 seconds (JVM running for 10.927)
2019-06-27 16:01:41.075 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 AUTH_MAP : {2147483647=admin, 0=visitor, 100=operator} 
********************
2019-06-27 16:01:41.076 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 4 ; CONFIGURATION_MAP : {modbus={1=读线圈, 2=读输入离散量, 3=读多个寄存器, 4=读输入寄存器, 5=写单个线圈, 6=写单个寄存器, 43=读设备识别码, 15=写多个线圈, 16=写多个寄存器, 20=读文件记录, 21=写文件记录, 22=屏蔽写寄存器, 23=读/写多个寄存器}, iec104={1=单点信息, 3=双点信息, 5=步位置信息, 7=32位比特串, 9=测量值，归一化值, 11=测量值，标度化值, 13=测量值，短浮点数, 15=累计量, 20=带状态检出的成组单点信息, 21=不带品质描述的归一化测量值, 30=带时标CP56Time2a的单点信息, 31=带时标CP56Time2a的双点信息, 32=带时标CP56Time2a的步位置信息, 33=带时标CP56Time2a的带时标CP56Time2a的32位比特串, 34=测量值，带时标CP56Time2a的归一化值, 35=测量值，带时标CP56Time2a的标度化值, 36=测量值，带时标CP56Time2a的短浮点数, 37=带时标CP56Time2a的累计量, 38=带时标CP56Time2a的继电保护装置事件, 39=带时标CP56Time2a的被控站成组启动事件, 40=带时标CP56Time2a的继电保护装置成组输出电路信息, 41=包含带时标的安全统计的累计量, 45=单命令, 46=双命令, 47=步调节命令, 48=设点命令，归一化值, 49=设点命令，标度化值, 50=设点命令，短浮点数, 51=32位比特串, 58=带时标CP56Time2a的单命令, 59=带时标CP56Time2a的双命令, 60=带时标CP56Time2a的步调节命令, 61=设点命令，带时标CP56Time2a的归一化值, 62=设点命令，带时标CP56Time2a的标度化值, 63=设点命令，带时标CP56Time2a的短浮点数, 64=带时标CP56Time2a的32比特串, 70=初始化结束, 81=身份认证质询, 82=身份认证响应, 83=主动模式身份认证请求会话密钥状态请求, 84=会话密钥状态请求, 85=会话密钥状态, 86=会话密钥变化, 87=身份认证错误, 90=用户状态变化, 91=更新密钥变化请求, 92=更新密钥变化响应, 93=更新对称密钥变化, 94=更新非对称密钥变化, 95=更新密钥变化配置, 100=总查询命令, 101=电能脉冲（计数器）查询命令, 102=读命令, 103=时钟同步命令, 105=复位进程命令, 107=带时标CP56Time2a的测试命令, 110=测量值参数，归一化值, 111=测量值参数，标度化值, 112=测量值参数，短浮点数, 113=参数激活, 120=文件已准备好, 121=节已准备好, 122=召唤目录；选择文件；召唤文件；召唤节, 123=最后的节，最后的段, 124=确认文件，确认节, 125=段, 126=目录, 127=日志查询-请求存档文件}, s7comm_job={0=CPU服务, 240=建立通信, 4=读取值, 5=写入值, 40=程序调用服务, 41=关闭PLC, 26=请求下载, 27=下载块, 28=下载结束, 29=开始上传, 30=上传, 31=上传结束}, opcaua={769=设置监控模式请求, 772=设置监控模式响应, 775=设置触发请求, 778=设置触发响应, 397=服务故障, 781=删除监控项请求, 527=浏览请求, 784=删除监控项响应, 530=浏览响应, 787=创建订阅请求, 533=浏览下一个请求, 790=创建订阅响应, 536=浏览下一个响应, 664=历史更新请求, 793=修改订阅请求, 410=测试堆栈请求, 667=历史更新响应, 796=修改订阅响应, 413=测试堆栈响应, 799=设置发布模式请求, 416=测试栈前请求, 673=写请求, 802=设置发布模式响应, 419=测试栈前响应, 676=写响应, 422=查询服务器请求, 425=查询服务器响应, 554=将浏览路径转换为节点ID的请求, 428=获取断点请求, 557=将浏览路径转换为节点ID的响应, 431=获取断点响应, 12208=查询在网服务器请求, 560=注册节点请求, 12209=查询在网服务器响应, 12211=注册要请求的服务器, 563=注册节点响应, 12212=注册要响应的服务器, 437=注册服务器请求, 566=注销节点请求, 440=注册服务器响应, 569=注销节点响应, 826=发布请求, 700=历史更新请求, 829=发布响应, 446=开放安全信道请求, 703=历史更新响应, 832=重新发布请求, 449=开放安全信道响应, 835=重新发布响应, 452=关闭安全信道请求, 455=关闭安全信道响应, 712=调用请求, 841=转移订阅请求, 715=调用响应, 844=转移订阅响应, 461=创建会话请求, 847=删除订阅请求, 464=创建会话响应, 850=删除订阅响应, 467=激活会话请求, 470=激活会话响应, 473=关闭会话请求, 476=关闭会话响应, 479=取消请求, 482=取消响应, 615=查询首项请求, 488=添加节点请求, 618=查询首项响应, 491=添加节点响应, 621=查询下一项请求, 494=添加引用请求, 751=创建监视项请求, 624=查询下一项响应, 497=添加引用响应, 754=创建监视项响应, 500=删除节点请求, 503=删除节点响应, 631=读取请求, 506=删除引用请求, 634=读取响应, 763=修改监视项请求, 509=删除引用响应, 766=修改监视项响应}}
********************
2019-06-27 16:01:41.077 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 21 ; PROTOCOL_STR_TO_INT : {1=modbus, 3=s7comm_job, 4=s7comm_ack_data, 5=tcp, 6=ipv4, 7=udp, 8=arp, 9=ipv6, 10=dns, 11=ethernet, 12=opcaua, 13=iec104, 14=dnp3.0, 15=nbns, 16=goose, 17=stp, 18=clnp, 19=esis, 20=icmpv6, 21=igmp, 22=lldp} 
********************
2019-06-27 16:01:41.077 packet-master-web [main] INFO  c.z.a.task.InitConfigurationService - 
******************** 
 size : 9 ; ALL_ART_CONFIG : [com.zjucsc.art_decode.artconfig.S7Config@694b1ddb, com.zjucsc.art_decode.artconfig.S7Config@6cc44207, com.zjucsc.art_decode.artconfig.S7Config@1ecec098, com.zjucsc.art_decode.artconfig.S7Config@7ebaf0d, com.zjucsc.art_decode.artconfig.S7Config@71fb1da3, com.zjucsc.art_decode.artconfig.S7Config@8ecc457, com.zjucsc.art_decode.artconfig.S7Config@61b0af9f, com.zjucsc.art_decode.artconfig.S7Config@21d3d6ec, com.zjucsc.art_decode.artconfig.S7Config@49f1184e] 
********************
2019-06-27 16:01:41.478 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：14
****************
2019-06-27 16:01:41.616 packet-master-web [kafka-producer-network-thread | client1] INFO  org.apache.kafka.clients.Metadata - Cluster ID: 8imxqaZ9QB-eWIBXAVsL-Q
2019-06-27 16:01:45.968 packet-master-web [scheduling-1] INFO  c.z.a.s.service.ScheduledService - 设备deb01252未添加StatisticInfoSaveBean，已重新添加，但程序中有错误...
2019-06-27 16:01:46.487 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-stopService
请求参数:[null]
请求结果:{"code":200,"data":{"cancelled":false,"completedExceptionally":false,"done":true,"numberOfDependents":0},"msg":"操作成功"}
耗时：0
****************
2019-06-27 16:01:51.490 packet-master-web [main] INFO  c.z.a.config.auth.LogAspect - info:
****************
请求类-方法：com.zjucsc.application.controller.PacketController-startCaptureService
请求参数:[null]
请求结果:{"code":200,"msg":"操作成功"}
耗时：1
****************
2019-06-27 16:02:01.502 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 16:02:01.504 packet-master-web [Thread-5] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 17:06:42.453 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 6828 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 17:06:42.475 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 17:06:44.681 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 17:06:44.788 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 17:06:44.918 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 57ms. Found 0 repository interfaces.
2019-06-27 17:06:45.890 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$25a2470a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 17:06:46.498 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 17:06:46.705 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 17:06:46.705 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 17:06:47.150 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 17:06:47.155 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 17:06:47.155 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 17:06:51.237 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 17:06:53.822 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 17:06:54.826 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 17:06:54.943 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 17:06:55.031 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 17:06:55.052 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 17:06:55.572 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 17:06:55.628 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 13.909 seconds (JVM running for 15.784)
2019-06-27 17:06:55.760 packet-master-web [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-27 17:06:55.791 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 17:06:55.793 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 17:07:23.071 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 16492 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 17:07:23.075 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 17:07:24.815 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 17:07:24.820 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 17:07:24.903 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 67ms. Found 0 repository interfaces.
2019-06-27 17:07:25.537 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$d4252db2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 17:07:25.879 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 17:07:26.035 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 17:07:26.035 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 17:07:26.429 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 17:07:26.435 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 17:07:26.435 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 17:07:28.875 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 17:07:30.414 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
2019-06-27 17:07:31.042 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService 'taskScheduler'
2019-06-27 17:07:31.135 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Context refreshed
2019-06-27 17:07:31.152 packet-master-web [main] INFO  s.d.s.w.p.DocumentationPluginsBootstrapper - Found 1 custom documentation plugin(s)
2019-06-27 17:07:31.165 packet-master-web [main] INFO  s.d.s.w.s.ApiListingReferenceScanner - Scanning for api listing references
2019-06-27 17:07:31.550 packet-master-web [main] INFO  s.d.s.w.r.o.CachingOperationNameGenerator - Generating unique operation named: selectPacketHistoryUsingPOST_1
2019-06-27 17:07:31.592 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Started PacketMasterWebApplicationTest in 9.135 seconds (JVM running for 10.268)
2019-06-27 17:07:31.714 packet-master-web [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-06-27 17:07:31.722 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler'
2019-06-27 17:07:31.725 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService
2019-06-27 20:40:08.926 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - Starting PacketMasterWebApplicationTest on DESKTOP-RJUOK47 with PID 14296 (started by CSE220 in E:\java_projects\capture-main)
2019-06-27 20:40:08.979 packet-master-web [main] INFO  c.z.PacketMasterWebApplicationTest - No active profile set, falling back to default profiles: default
2019-06-27 20:40:10.583 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2019-06-27 20:40:10.586 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data repositories in DEFAULT mode.
2019-06-27 20:40:10.671 packet-master-web [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 69ms. Found 0 repository interfaces.
2019-06-27 20:40:11.327 packet-master-web [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$c2ec52cd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-06-27 20:40:11.697 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 20:40:11.853 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 20:40:11.853 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 20:40:12.252 packet-master-web [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [10.15.191.100:9092]
	buffer.memory = 33554432
	client.id = client1
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2019-06-27 20:40:12.258 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
2019-06-27 20:40:12.258 packet-master-web [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
2019-06-27 20:40:15.146 packet-master-web [main] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
2019-06-27 20:40:16.564 packet-master-web [main] INFO  o.s.b.a.w.s.WelcomePageHandlerMapping - Adding welcome page: class path resource [static/index.html]
2019-06-27 20:40:16.852 packet-master-web [main] INFO  o.s.s.c.ThreadPoolTaskScheduler - Initializing ExecutorService
